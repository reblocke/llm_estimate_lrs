{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Scraper and Estimator\n",
    "\n",
    "Overall, this notebook contains code to scrape diagnostic likelihood ratios from theNNT.com and convert them to numerical form. \n",
    "\n",
    "It also contains code to generate prompts for large language models to estimate the likelihood ratios. \n",
    "\n",
    "The output is a spreadsheet called: nnt_lrs_with_estimated which contains: \n",
    "- a sheet for each diagnosis or prediction target\n",
    "- a row for each piece of information\n",
    "- columns for the name, raw nnt lr, processed nnt lr, and estimated by 1 or more LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data from the NNT \n",
    "\n",
    "This scrapes all of the likelihood ratios listed on the NNT ('https://thennt.com/home-lr/') into Excel spreadsheets. \n",
    "\n",
    "1. A spreadsheet (\"nnt_lrs.xlsx\") contains a separate sheet for each page, which corresponds to a \"prediction tasks\" e.g. diagnosing the cause of a symptom - sometimes with specification of an intended population. Each sheet contains two columns: the name of the features (e.g. test result, finding, historical occurence, comorbditiy), the second contains the raw listing from the spreadsheet\n",
    "\n",
    "2. A second spreadsheet contains the same sheets corresponding to a prediction target, and all of the features. These are used two call the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI  # or your appropriate client wrapper\n",
    "import math\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # looks for a .env file in the current dir by default\n",
    "#print(os.getenv(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching pages for Specialty: Anesthesiology\n",
      "  - Fetching: Diagnostic Accuracy of Ultrasound for Confirmation of Endotracheal Tube Placement (https://thennt.com/lr/diagnostic-accuracy-ultrasound-confirmation-endotracheal-tube-placement/)\n",
      "    Success: Diagnostic Accuracy of Ultrasound for Confirmation of Endotracheal Tube Placement page fetched.\n",
      "  - Fetching: Factors Predicting Difficult Endotracheal Intubation (https://thennt.com/lr/factors-predicting-difficult-endotracheal-intubation/)\n",
      "    Success: Factors Predicting Difficult Endotracheal Intubation page fetched.\n",
      "\n",
      "\n",
      "Fetching pages for Specialty: Cardiology\n",
      "  - Fetching: Acute Coronary Syndrome (https://thennt.com/lr/acute-coronary-syndrome/)\n",
      "    Success: Acute Coronary Syndrome page fetched.\n",
      "  - Fetching: Aortic Dissection (https://thennt.com/lr/aortic-dissection/)\n",
      "    Success: Aortic Dissection page fetched.\n",
      "  - Fetching: Deep Venous Thrombosis (DVT) (https://thennt.com/lr/deep-venous-thrombosis-dvt/)\n",
      "    Success: Deep Venous Thrombosis (DVT) page fetched.\n",
      "  - Fetching: Dyspnea Due to Acute Heart Failure Syndrome (https://thennt.com/lr/dyspnea-due-acute-heart-failure-syndrome/)\n",
      "    Success: Dyspnea Due to Acute Heart Failure Syndrome page fetched.\n",
      "  - Fetching: Dyspnea Due to Heart Failure (With Chronic Respiratory Disease) (https://thennt.com/lr/dyspnea-due-to-heart-failure-with-chronic-respiratory-disease/)\n",
      "    Success: Dyspnea Due to Heart Failure (With Chronic Respiratory Disease) page fetched.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 296\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Fetch specialties and links\u001b[39;00m\n\u001b[1;32m    295\u001b[0m specialty_links \u001b[38;5;241m=\u001b[39m get_specialty_links()\n\u001b[0;32m--> 296\u001b[0m findings_data \u001b[38;5;241m=\u001b[39m fetch_webpages(specialty_links)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;66;03m# Save normal file\u001b[39;00m\n\u001b[1;32m    299\u001b[0m save_to_excel(findings_data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnnt_lrs.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, blank_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[3], line 257\u001b[0m, in \u001b[0;36mfetch_webpages\u001b[0;34m(specialty_links)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Failed to fetch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Status Code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 257\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Optional: Add a delay to avoid overwhelming the server\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Error fetching \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_specialty_links():\n",
    "    \"\"\"\n",
    "    Extracts specialties and their corresponding article links from the webpage.\n",
    "    Returns a list of dictionaries with specialty names and associated links.\n",
    "    \"\"\"\n",
    "\n",
    "    url = 'https://thennt.com/home-lr/'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Locate the section with \"Diagnosis (LR) Reviews by Specialty\"\n",
    "    specialty_section = soup.find('div', class_='well subdisplay accordion_caption', id='lr-byspecialty')\n",
    "\n",
    "    if not specialty_section:\n",
    "        print(\"Could not find the 'Diagnosis (LR) Reviews by Specialty' section on the webpage.\")\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Find all specialty headings (e.g., h3)\n",
    "    subheadings = specialty_section.find_all('h3')\n",
    "\n",
    "    for subheading in subheadings:\n",
    "        subheading_text = subheading.get_text(strip=True)  # Get specialty name\n",
    "        links = []\n",
    "\n",
    "        # Find the next unordered list (ul) which contains links\n",
    "        next_ul = subheading.find_next_sibling('ul')\n",
    "\n",
    "        if next_ul:\n",
    "            for a_tag in next_ul.find_all('a', href=True):\n",
    "                link_text = a_tag.get_text(strip=True)  # Link display name\n",
    "                link_href = a_tag['href']  # Actual URL\n",
    "                links.append({'display_name': link_text, 'url': link_href})\n",
    "\n",
    "        results.append({'specialty': subheading_text, 'links': links})\n",
    "\n",
    "    return results\n",
    "\n",
    "def extract_likelihood_ratios(page_content):\n",
    "    \"\"\"\n",
    "    Parses all likelihood ratio tables within <article class=\"lr_cards_details\">.\n",
    "    For each subsection indicated by an <h3> heading:\n",
    "      - If the heading indicates Positive Findings, each finding will be prefixed with \"Patient has: \".\n",
    "      - If the heading indicates Negative Findings, a leading \"No\" (if present) is removed from the finding and then it is prefixed with \"Patient does not have: \".\n",
    "    This function processes all tables under a given heading (i.e. until the next <h3> is reached).\n",
    "    Returns a list of tuples: (finding, likelihood ratio).\n",
    "    \"\"\"\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    results = []\n",
    "    \n",
    "    # Locate the main LR details section.\n",
    "    lr_section = soup.find('article', class_='lr_cards_details')\n",
    "    if not lr_section:\n",
    "        return results\n",
    "\n",
    "    # Find all <h3> headings in the section.\n",
    "    headings = lr_section.find_all('h3')\n",
    "    \n",
    "    if headings:\n",
    "        for h3 in headings:\n",
    "            heading_text = h3.get_text(strip=True)\n",
    "            if \"Positive Findings\" in heading_text:\n",
    "                prefix = \"Patient has: \"\n",
    "            elif \"Negative Findings\" in heading_text:\n",
    "                prefix = \"Patient does not have: \"\n",
    "            else:\n",
    "                prefix = \"\"\n",
    "            \n",
    "            # Process all sibling elements until the next <h3> is encountered.\n",
    "            sibling = h3.find_next_sibling()\n",
    "            while sibling and sibling.name != \"h3\":\n",
    "                if sibling.name == \"table\" and \"lrtable\" in sibling.get(\"class\", []):\n",
    "                    # Try to get proper data rows (i.e. <tr> elements with <td>).\n",
    "                    rows = sibling.find_all(\"tr\")\n",
    "                    data_rows = [row for row in rows if row.find_all(\"td\")]\n",
    "                    \n",
    "                    if data_rows:\n",
    "                        for row in data_rows:\n",
    "                            cols = row.find_all(\"td\")\n",
    "                            if len(cols) >= 2:\n",
    "                                finding = cols[0].get_text(strip=True)\n",
    "                                lr_value = cols[1].get_text(strip=True)\n",
    "                                # If there's an <a> inside the LR cell, use its text.\n",
    "                                link = cols[1].find(\"a\")\n",
    "                                if link:\n",
    "                                    lr_value = link.get_text(strip=True) or lr_value\n",
    "                                if not lr_value:\n",
    "                                    lr_value = \"Not reported\"\n",
    "                                \n",
    "                                # Modify the finding string based on the prefix.\n",
    "                                if prefix:\n",
    "                                    if prefix.startswith(\"Patient does not have:\"):\n",
    "                                        finding = re.sub(r'^no\\s+', '', finding, flags=re.IGNORECASE)\n",
    "                                    finding = prefix + finding\n",
    "                                \n",
    "                                results.append((finding, lr_value))\n",
    "                    else:\n",
    "                        # If no rows with <td> are found, assume the table contains <td> elements in sequence.\n",
    "                        all_tds = sibling.find_all(\"td\")\n",
    "                        # Process in pairs.\n",
    "                        for i in range(0, len(all_tds), 2):\n",
    "                            finding = all_tds[i].get_text(strip=True)\n",
    "                            if i+1 < len(all_tds):\n",
    "                                lr_value = all_tds[i+1].get_text(strip=True)\n",
    "                            else:\n",
    "                                lr_value = \"Not reported\"\n",
    "                            # Check for an <a> element.\n",
    "                            a_tag = all_tds[i+1].find(\"a\")\n",
    "                            if a_tag:\n",
    "                                lr_value = a_tag.get_text(strip=True) or lr_value\n",
    "                            if not lr_value:\n",
    "                                lr_value = \"Not reported\"\n",
    "                            \n",
    "                            if prefix:\n",
    "                                if prefix.startswith(\"Patient does not have:\"):\n",
    "                                    finding = re.sub(r'^no\\s+', '', finding, flags=re.IGNORECASE)\n",
    "                                finding = prefix + finding\n",
    "                            results.append((finding, lr_value))\n",
    "                sibling = sibling.find_next_sibling()\n",
    "    else:\n",
    "        # Fallback: process all tables in the section if no <h3> headings exist.\n",
    "        tables = lr_section.find_all('table', class_='lrtable')\n",
    "        for table in tables:\n",
    "            rows = table.find_all(\"tr\")\n",
    "            data_rows = [row for row in rows if row.find_all(\"td\")]\n",
    "            if data_rows:\n",
    "                for row in data_rows:\n",
    "                    cols = row.find_all(\"td\")\n",
    "                    if len(cols) >= 2:\n",
    "                        finding = cols[0].get_text(strip=True)\n",
    "                        lr_value = cols[1].get_text(strip=True)\n",
    "                        link = cols[1].find(\"a\")\n",
    "                        if link:\n",
    "                            lr_value = link.get_text(strip=True) or lr_value\n",
    "                        if not lr_value:\n",
    "                            lr_value = \"Not reported\"\n",
    "                        results.append((finding, lr_value))\n",
    "            else:\n",
    "                all_tds = table.find_all(\"td\")\n",
    "                for i in range(0, len(all_tds), 2):\n",
    "                    finding = all_tds[i].get_text(strip=True)\n",
    "                    if i+1 < len(all_tds):\n",
    "                        lr_value = all_tds[i+1].get_text(strip=True)\n",
    "                    else:\n",
    "                        lr_value = \"Not reported\"\n",
    "                    a_tag = all_tds[i+1].find(\"a\") if i+1 < len(all_tds) else None\n",
    "                    if a_tag:\n",
    "                        lr_value = a_tag.get_text(strip=True) or lr_value\n",
    "                    if not lr_value:\n",
    "                        lr_value = \"Not reported\"\n",
    "                    results.append((finding, lr_value))\n",
    "                    \n",
    "    return results\n",
    "\n",
    "\"\"\"\n",
    "def extract_likelihood_ratios(page_content):\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    results = []\n",
    "\n",
    "    # Locate the section containing likelihood ratio tables\n",
    "    lr_section = soup.find('article', class_='lr_cards_details')\n",
    "    if not lr_section:\n",
    "        return results  # Return empty if no section found\n",
    "\n",
    "    # Find all tables inside the LR card\n",
    "    tables = lr_section.find_all('table', class_='lrtable')\n",
    "\n",
    "    for table in tables:\n",
    "        # Grab all <tr> elements\n",
    "        all_rows = table.find_all('tr')\n",
    "\n",
    "        # Filter out any row that only has <th> (i.e., a header row)\n",
    "        data_rows = []\n",
    "        for row in all_rows:\n",
    "            # If there's at least one <td> in this row, treat it as a data row\n",
    "            if row.find_all('td'):\n",
    "                data_rows.append(row)\n",
    "\n",
    "        # If we have real data rows, parse them\n",
    "        if data_rows:\n",
    "            for row in data_rows:\n",
    "                cols = row.find_all('td')\n",
    "                # If the row has exactly 2 <td>, treat them as (finding, LR)\n",
    "                if len(cols) == 2:\n",
    "                    finding = cols[0].get_text(strip=True)\n",
    "                    lr_value = cols[1].get_text(strip=True)\n",
    "                    # If there's an <a> inside the LR cell, grab its text\n",
    "                    link = cols[1].find('a')\n",
    "                    if link:\n",
    "                        lr_value = link.get_text(strip=True) or lr_value\n",
    "                    if not lr_value:\n",
    "                        lr_value = \"Not reported\"\n",
    "\n",
    "                    results.append((finding, lr_value))\n",
    "\n",
    "        else:\n",
    "            # Fallback: if there are no valid data rows, we process all <td> in pairs\n",
    "            cols = table.find_all('td')\n",
    "            for i in range(0, len(cols) - 1, 2):\n",
    "                finding = cols[i].get_text(strip=True)\n",
    "                lr_value_element = cols[i + 1]\n",
    "\n",
    "                # Extract the likelihood ratio, handling nested <a> and <br/>\n",
    "                link = lr_value_element.find('a')\n",
    "                if link:\n",
    "                    lr_value = link.get_text(strip=True)\n",
    "                else:\n",
    "                    lr_value = lr_value_element.get_text(strip=True)\n",
    "\n",
    "                if not lr_value:\n",
    "                    lr_value = \"Not reported\"\n",
    "\n",
    "                results.append((finding, lr_value))\n",
    "\n",
    "    return results\n",
    "\"\"\"\n",
    "    \n",
    "def fetch_webpages(specialty_links):\n",
    "    \"\"\"\n",
    "    Iterates through all the extracted links, fetches the webpage content, \n",
    "    and extracts likelihood ratio findings.\n",
    "    \"\"\"\n",
    "    findings_by_display_name = {}\n",
    "\n",
    "    for item in specialty_links:\n",
    "        print(f\"Fetching pages for Specialty: {item['specialty']}\")\n",
    "\n",
    "        for link in item['links']:\n",
    "            display_name = link['display_name']\n",
    "            url = link['url']\n",
    "\n",
    "            try:\n",
    "                print(f\"  - Fetching: {display_name} ({url})\")\n",
    "                response = requests.get(url)\n",
    "\n",
    "                if response.status_code == 200:\n",
    "                    print(f\"    Success: {display_name} page fetched.\")\n",
    "                    \n",
    "                    # Extract likelihood ratio findings\n",
    "                    findings = extract_likelihood_ratios(response.text)\n",
    "                    \n",
    "                    # Store the extracted data\n",
    "                    findings_by_display_name[display_name] = findings\n",
    "\n",
    "                else:\n",
    "                    print(f\"    Failed to fetch {display_name} - Status Code: {response.status_code}\")\n",
    "\n",
    "                time.sleep(1)  # Optional: Add a delay to avoid overwhelming the server\n",
    "\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"    Error fetching {display_name}: {e}\")\n",
    "\n",
    "        print(\"\\n\")  # Add space between specialties for readability\n",
    "\n",
    "    return findings_by_display_name\n",
    "\n",
    "def save_to_excel(findings_data, filename=\"nnt_lrs.xlsx\", blank_values=False):\n",
    "    \"\"\"\n",
    "    Saves likelihood ratios to an Excel file with each display_name as a separate sheet.\n",
    "    If blank_values is True, the Likelihood Ratio column is left blank.\n",
    "    The first row contains the full display_name, and column headers start from the second row.\n",
    "    \"\"\"\n",
    "    with pd.ExcelWriter(filename, engine=\"openpyxl\") as writer:\n",
    "        for display_name, findings in findings_data.items():\n",
    "            if findings:\n",
    "                # Prepare DataFrame\n",
    "                df = pd.DataFrame(findings, columns=[\"Finding\", \"Likelihood Ratio\"])\n",
    "\n",
    "                if blank_values:\n",
    "                    df[\"Likelihood Ratio\"] = \"\"  # Clear likelihood ratio values\n",
    "\n",
    "                # Insert full display_name as the first row\n",
    "                full_name_row = pd.DataFrame({df.columns[0]: [display_name], df.columns[1]: [\"\"]})\n",
    "                df = pd.concat([full_name_row, df], ignore_index=True)\n",
    "\n",
    "                # Save to Excel with sheet name as the **last** 31 characters\n",
    "                sheet_name = display_name[-31:]\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)  # No default header\n",
    "\n",
    "            else:\n",
    "                print(f\"Skipping {display_name} (No data found).\")\n",
    "\n",
    "    print(f\"\\nLikelihood ratios saved to {filename}\")\n",
    "\n",
    "# Fetch specialties and links\n",
    "specialty_links = get_specialty_links()\n",
    "findings_data = fetch_webpages(specialty_links)\n",
    "\n",
    "# Save normal file\n",
    "save_to_excel(findings_data, \"nnt_lrs.xlsx\", blank_values=False)\n",
    "\n",
    "# Save version with blank likelihood ratios\n",
    "save_to_excel(findings_data, \"nnt_lrs_sans_number.xlsx\", blank_values=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert LR's to numerical format\n",
    "\n",
    "This block takes in the excel spreadsheet with raw data from theNNT.com (\"nnt_lrs.xlsx\") and creates a new spreadsheet (\"nnt_lrs_processed.xlsx\") with a third column that contains a numerical version of the second column (raw data from theNNT) to be used as the LR_llm.\n",
    "\n",
    "\n",
    "It removes any 'x's from the input, then determines whether the cell reports \n",
    "\n",
    "1. point estimate only (in which case use the point estimate)\n",
    "2. point estimate + range (in which case take the point estimate), or \n",
    "3. range only (in which case, calculate the geometric mean)\n",
    "\n",
    "It also counts the number of conditions (last 31 letters due to excel limitation) and LRs\n",
    "\n",
    "\n",
    "[ ] TODO: \n",
    "- some of the BNP thresholds just have a number rather than a specification of the full \"BNP > 100\"; need to use header e.g. https://thennt.com/lr/dyspnea-due-to-heart-failure-without-chronic-respiratory-disease/ and https://thennt.com/lr/dyspnea-due-to-heart-failure-without-chronic-respiratory-disease/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 30 condition(s) (sheets).\n",
      "Sheet ' of Endotracheal Tube Placement' has 2 LR value(s).\n",
      "Sheet 'fficult Endotracheal Intubation' has 14 LR value(s).\n",
      "Sheet 'Acute Coronary Syndrome' has 90 LR value(s).\n",
      "Sheet 'Aortic Dissection' has 18 LR value(s).\n",
      "Sheet 'Deep Venous Thrombosis (DVT)' has 6 LR value(s).\n",
      "Sheet 'to Acute Heart Failure Syndrome' has 12 LR value(s).\n",
      "Sheet 'th Chronic Respiratory Disease)' has 56 LR value(s).\n",
      "Sheet 'ut Chronic Respiratory Disease)' has 92 LR value(s).\n",
      "Sheet 'modynamically Unstable Patients' has 3 LR value(s).\n",
      "Sheet 'he Diagnosis of Cardiac Syncope' has 20 LR value(s).\n",
      "Sheet ' Elevated Intracranial Pressure' has 6 LR value(s).\n",
      "Sheet 'in Penetrating Extremity Trauma' has 2 LR value(s).\n",
      "Sheet 'trasound for Retinal Detachment' has 2 LR value(s).\n",
      "Sheet 'esting for Giant Cell Arteritis' has 10 LR value(s).\n",
      "Sheet 'tion of Small Bowel Obstruction' has 2 LR value(s).\n",
      "Sheet 'f Diagnostic Tests for Syphilis' has 6 LR value(s).\n",
      "Sheet 'gnosis of Pneumonia in Children' has 2 LR value(s).\n",
      "Sheet 'nal Injuries After Blunt Trauma' has 2 LR value(s).\n",
      "Sheet 'cute Onset Flashes and Floaters' has 5 LR value(s).\n",
      "Sheet 'Hypovolemia' has 22 LR value(s).\n",
      "Sheet 'Malaria in Returning Travelers' has 28 LR value(s).\n",
      "Sheet 'eomyelitis in Diabetic Patients' has 15 LR value(s).\n",
      "Sheet 'Pertussis (Whooping Cough)' has 6 LR value(s).\n",
      "Sheet 'Streptococal Pharyngitis' has 49 LR value(s).\n",
      "Sheet 'Hemorrhagic Stroke' has 56 LR value(s).\n",
      "Sheet 'Migraine' has 1 LR value(s).\n",
      "Sheet 'Myasthenia Gravis' has 15 LR value(s).\n",
      "Sheet 'Spinal Stenosis in the Elderly' has 68 LR value(s).\n",
      "Sheet 'Temporal Arteritis' has 56 LR value(s).\n",
      "Sheet 'Carpal Tunnel Syndrome' has 34 LR value(s).\n",
      "Total LR values processed across all sheets: 700.\n",
      "Processed Excel file saved as 'nnt_lrs_processed.xlsx'\n"
     ]
    }
   ],
   "source": [
    "def parse_lr(lr_str):\n",
    "    \"\"\"\n",
    "    Given a string from the 'Likelihood Ratio' cell, this function:\n",
    "      - Removes any 'x' characters from the input.\n",
    "      - If the string contains a parenthesized range (i.e. a point estimate plus a range),\n",
    "        it returns the point estimate.\n",
    "      - If the entire string is a range (e.g. \"0.92-1.1\", \"3.3 to 4.8\", \"4.8–7.6\"),\n",
    "        it computes and returns the geometric mean.\n",
    "      - Otherwise, it returns a float based on the first number found.\n",
    "      - If the value is missing or cannot be parsed, returns NaN.\n",
    "    \"\"\"\n",
    "    # Remove all 'x' characters and trim whitespace\n",
    "    lr_str = lr_str.replace(\"x\", \"\").strip()\n",
    "    if lr_str == \"\":\n",
    "        return np.nan\n",
    "\n",
    "    # If parentheses exist, assume format \"point_estimate (range)\" and use the point estimate.\n",
    "    if \"(\" in lr_str:\n",
    "        point_part = lr_str.split(\"(\")[0].strip()\n",
    "        try:\n",
    "            return float(point_part)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Check for a range-only pattern.\n",
    "    # This regex looks for two numbers separated by \"to\", \"-\" or \"–\" with optional whitespace.\n",
    "    range_only_match = re.match(r'^\\s*([0-9]*\\.?[0-9]+)\\s*(to|[-–])\\s*([0-9]*\\.?[0-9]+)\\s*$', lr_str)\n",
    "    if range_only_match:\n",
    "        try:\n",
    "            low = float(range_only_match.group(1))\n",
    "            high = float(range_only_match.group(3))\n",
    "            return math.sqrt(low * high)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    # Fallback: if no range-only pattern is found, extract the first number and return it.\n",
    "    numbers = re.findall(r'([0-9]*\\.?[0-9]+)', lr_str)\n",
    "    if numbers:\n",
    "        try:\n",
    "            return float(numbers[0])\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "# Load the original Excel file (each sheet has no header and the first row is the display name row)\n",
    "input_filename = \"nnt_lrs.xlsx\"\n",
    "output_filename = \"nnt_lrs_processed.xlsx\"\n",
    "\n",
    "# Read all sheets from the Excel file into a dictionary of DataFrames.\n",
    "excel_sheets = pd.read_excel(input_filename, sheet_name=None, header=None)\n",
    "\n",
    "total_lr_count = 0\n",
    "sheet_counts = {}\n",
    "\n",
    "with pd.ExcelWriter(output_filename, engine=\"openpyxl\") as writer:\n",
    "    for sheet_name, df in excel_sheets.items():\n",
    "        numerical_lr = []\n",
    "        # Process each row in the sheet.\n",
    "        for idx, row in df.iterrows():\n",
    "            # For the header row (assumed to be the first row: condition label), add an empty string.\n",
    "            if idx == 0:\n",
    "                numerical_lr.append(\"\")\n",
    "            else:\n",
    "                cell_value = row[1]  # The original \"Likelihood Ratio\" is in the second column (index 1)\n",
    "                if pd.isna(cell_value) or str(cell_value).strip() == \"\":\n",
    "                    numerical_lr.append(\"\")\n",
    "                else:\n",
    "                    numerical_lr.append(parse_lr(str(cell_value)))\n",
    "        \n",
    "        # Insert the new column immediately after the \"Likelihood Ratio\" column.\n",
    "        # This makes the new column the third column.\n",
    "        df.insert(2, \"Numerical LR\", numerical_lr)\n",
    "        \n",
    "        # Remove rows (except the header) where the new \"Numerical LR\" is empty or NaN.\n",
    "        header = df.iloc[[0]]  # Keep the header row (the condition label)\n",
    "        data = df.iloc[1:]\n",
    "        data = data[data[\"Numerical LR\"].apply(lambda x: not (x == \"\" or pd.isna(x)))]\n",
    "        filtered_df = pd.concat([header, data], ignore_index=True)\n",
    "        \n",
    "        # Insert a new row (after the condition label row) with the column labels.\n",
    "        # The final sheet will have:\n",
    "        #   Row 0: Condition label (from the original sheet)\n",
    "        #   Row 1: Column labels: 'finding', 'lr_raw', and 'lr_num'\n",
    "        #   Row 2+: Data rows\n",
    "        col_labels = pd.DataFrame([[\"finding\", \"lr_raw\", \"lr_reported\"]], columns=filtered_df.columns)\n",
    "        final_df = pd.concat([filtered_df.iloc[[0]], col_labels, filtered_df.iloc[1:]], ignore_index=True)\n",
    "        \n",
    "        # Count the number of LR values for this sheet (exclude the two header rows).\n",
    "        lr_count = len(final_df) - 2\n",
    "        sheet_counts[sheet_name] = lr_count\n",
    "        total_lr_count += lr_count\n",
    "        \n",
    "        # Write the modified DataFrame to the new Excel file.\n",
    "        # The output maintains the original format: no index and no additional header row.\n",
    "        final_df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)\n",
    "\n",
    "# Display counts.\n",
    "num_sheets = len(excel_sheets)\n",
    "print(f\"Processed {num_sheets} condition(s) (sheets).\")\n",
    "for sheet, count in sheet_counts.items():\n",
    "    print(f\"Sheet '{sheet}' has {count} LR value(s).\")\n",
    "print(f\"Total LR values processed across all sheets: {total_lr_count}.\")\n",
    "\n",
    "print(f\"Processed Excel file saved as '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate LRs\n",
    "\n",
    "NOTE: for the real run at this, we'll want to do some manual editing of the info columns - as there are some where it is a lab value that references the preceeding value (not currently automated to account for). \n",
    "--- particularly, BNP thresholds in the cardiac-cause sheets. \n",
    "\n",
    "\n",
    "This code block reads in the data from the nnt_lr_processed.xlsx excel file and calls a list of openAI models to have them give there best (single) estimate of the LR. Then, it rights a new spreadsheet nnt_lr_estimates that includes columns in each spreadsheet for each estimation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosis: 'Diagnostic Accuracy of Ultrasound for Confirmation of Endotracheal Tube Placement', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Factors Predicting Difficult Endotracheal Intubation', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Acute Coronary Syndrome', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Aortic Dissection', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Deep Venous Thrombosis (DVT)', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Dyspnea Due to Acute Heart Failure Syndrome', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Dyspnea Due to Heart Failure (With Chronic Respiratory Disease)', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Dyspnea Due to Heart Failure (Without Chronic Respiratory Disease)', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Markers of Fluid Responsiveness in Hemodynamically Unstable Patients', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Use of the Clinical Examination in the Diagnosis of Cardiac Syncope', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Accuracy of Physical Examination and Imaging Findings for the Diagnosis of Elevated Intracranial Pressure', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Ankle-Brachial Index for Diagnosis of Arterial Injury in Penetrating Extremity Trauma', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Diagnostic Accuracy of Point-of-Care Ultrasound for Retinal Detachment', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Diagnostic Accuracy of the History, Physical Examination, and Laboratory Testing for Giant Cell Arteritis', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Diagnostic Accuracy of Ultrasound for the Evaluation of Small Bowel Obstruction', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Operating Characteristics of Diagnostic Tests for Syphilis', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Lung Ultrasound for Diagnosis of Pneumonia in Children', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Point-of-Care Ultrasound for the Diagnosis of Thoracoabdominal Injuries After Blunt Trauma', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Retinal Pathology in Patients with Acute Onset Flashes and Floaters', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Hypovolemia', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Malaria in Returning Travelers', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Osteomyelitis in Diabetic Patients', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Pertussis (Whooping Cough)', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Streptococal Pharyngitis', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Hemorrhagic Stroke', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Migraine', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Myasthenia Gravis', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Spinal Stenosis in the Elderly', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Temporal Arteritis', Model: 'o3-2025-04-16'\n",
      "Diagnosis: 'Carpal Tunnel Syndrome', Model: 'o3-2025-04-16'\n",
      "Processed Excel file saved as 'nnt_lrs_with_estimated.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Define the response schema expecting a floating point number.\n",
    "class LRResponse(BaseModel):\n",
    "    value: float\n",
    "\n",
    "def estimate_lr(diagnosis: str, info_val: str, client, model: str) -> float:\n",
    "    \"\"\"\n",
    "    Calls the LLM with a prompt containing the diagnosis and a finding.\n",
    "    Returns the estimated likelihood ratio as a floating point number.\n",
    "    \"\"\"\n",
    "    lr_prompt = \"\"\"You are an expert in medical diagnosis who is giving assessments of how important a piece of information is when determining whether a patient has a particularly condition. Your task is to estimate the likelihood ratio of a finding for a disease. Recall that the likelihood ratio represents how much the ratio between the odds of disease given a result for a lab value, whether a physical exam finding is present, or whether a comorbidity is present over the odds of disease when you did not know the result.\n",
    "You will receive inputs in the following format; Target condition: <Condition, e.g. Patient Has: Cardiac chest pain>. Finding: <piece of information, e.g. ‘Patient does not have: radiation to the neck, arm, or jaw’>.\n",
    "So, for example. If the odds of a Condition Z being present was 1 (meaning 50% probability) before we knew anything, but then we got a result (Finding A) it became 2 (meaning 2:1 odds or 66% probability), then the likelihood ratio would be 2. \n",
    "Given a condition and a finding, you will provide your best estimate of the likelihood ratio as a floating point number. Return your answer in valid JSON with the following schema: { 'value': <floating point number greater than 0> }.\\n\\n\n",
    "\n",
    "Remember, stronger evidence in favor of a condition has a value farther above 1. Strong evidence against a diagnosis has a value farther below 1 (closer to 0). A likelihood ratio of 10 is equally strong evidence for a condition as a likelihood ratio of 0.1 is against it. Likelihood ratios near 1 represent weak evidence for or against. \n",
    "And if the \"patient does not have: \" some feature that is almost always present, that is strong evidence against.\n",
    "(pay attention for double negatives- Patient has: no tobacco and Patient does not have: tobacco are identical)\n",
    "\n",
    "Here is how I would like you to approach the problem:\n",
    "First, consider the condition you are predicting (Condition: ___). Is the condition a medical diagnosis? If so, what kind of findings are usually present in someone who has that condition. Does the condition specify a certain type of patient? If so, how does that change things? \n",
    "Then, consider the finding. If a finding is much more common among patients who have the condition of interest than among patients who do not have the condition of interest, then the likelihood ratio should be high. This might be because the finding is a consequence of the disease, indicates that an enabling condition is present, indicates that a frequently comorbid condition is present, or is related to the pathology of the condition. In general, likelihood ratios over about 20 are pathognomonic, above 5 or so is extremely strong evidence in favor, above 2.5 or so is strong evidence, above 1.4 is so-so evidence, and 1-1.4 is pretty weak evidence. Conversely, if the finding is more common in people who do NOT have the condition, then the likelihood ratio should be below 1. Similarly, a likelihood ratio below 0.05 would exclude the condition in most situations, below 0.2 would be extremely strong evidence against, below 0.4 would be strong evidence against, below 0.71 is so-so, and between 0.71 and 1 is pretty weak evidence against (meaning, it just doesn’t change the odds of the condition much). \n",
    "\n",
    "Here are some hypothetical examples to consider: \n",
    "    Prompt = Target condition: Cardiac Chest Pain. Finding: Patient has: Pain not worse with exertion (requires they clarify exercise 1hr after meal).\n",
    "    You would reason that because cardiac chest pain is usually worse with exertion because exertion worsens cardiac demand for oxygen, and thus worsens ischemia.\n",
    "    Response = {\n",
    "        ‘value’: 0.4\n",
    "    }\n",
    "\n",
    "    Prompt =  Target condition: Cardiac Chest Pain. Finding: Patient does not have: tobacco.\n",
    "    You would reason that because being someone who smokes increases your risk of coronary artery disease, and thus being a never smoker means you’re at less risk… but many people who have heart attacks still smoke, so it’s only a weak predictor. \n",
    "    Response = {\n",
    "        ‘value’: 0.75\n",
    "    }\n",
    "\n",
    "    Prompt = Target condition: Cardaic Chest Pain. Finding = Patient has: enjoys playing chess.\n",
    "    You would reason that because enjoying chest has no relationship to having a heart attack.\n",
    "    Response = {\n",
    "        ‘value’: 1\n",
    "    }\n",
    "\n",
    "    Prompt = Target condition: Cardiac Chest Pain. Finding = Patient has: pain located behind the sternum\n",
    "    You would reason that because cardiac chest pain is often experienced behind the sternum (thus, more likely), but so are many other causes of chest pain - like GERD.\n",
    "    Response = {\n",
    "        ‘value’: 1.2\n",
    "    }\n",
    "\n",
    "    Prompt = Condition: Cardiac Chest Pain. Finding = patient has: pain worse with exertion.\n",
    "    You would reason that because the increased myocardial oxygen consumption worsens the pain if oxygen delivery to the myocardium is the cause, as it is in heart attacks.\n",
    "    Response = {\n",
    "        ‘value’: 3.4\n",
    "    }\n",
    "\n",
    "    OK: here’s the prompt.. \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": lr_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Condition: {diagnosis}\\nFinding: {info_val}\"}\n",
    "    ]\n",
    "\n",
    "    # Check if the model starts with \"o3-mini\" \"o3\" \"o4-mini, \"o4\", etc.\n",
    "    kwargs = {}\n",
    "    if model.startswith(\"o\"):\n",
    "        kwargs[\"reasoning_effort\"] = \"medium\"  # low, medium, high depending on need\n",
    "\n",
    "    # Call the LLM using the provided model name.\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        response_format=LRResponse,\n",
    "        **kwargs  # pass the conditional keyword argument\n",
    "    )\n",
    "\n",
    "    # Call the LLM using the provided model name.\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=model,  # use the current model from the list\n",
    "        messages=messages,\n",
    "        response_format=LRResponse,\n",
    "    )\n",
    "    \n",
    "    # Extract and return the floating point estimate.\n",
    "    lr_response = completion.choices[0].message.parsed\n",
    "    return lr_response.value\n",
    "\n",
    "\n",
    "# Initialize the OpenAI (or your chosen) client using your API key.\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# List of model names to iterate over.\n",
    "model_names = ['gpt-4o-mini-2024-07-18', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-2025-04-14', 'o4-mini-2025-04-16'] #'gpt-4o-2024-08-06', 'o3-mini-2025-01-31', gpt-4.1-2025-04-14, o4-mini-2025-04-16, 'o3-2025-04-16']\n",
    "\n",
    "# Read the processed Excel file.\n",
    "# We use header=None so that row 0 (the diagnosis row) and row 1 (the column headers row) are preserved.\n",
    "input_filename = \"nnt_lrs_processed.xlsx\"\n",
    "#input_filename = \"new_\" \\\n",
    "#\"nnt_lrs_processed.xlsx\" # use this one for the substitute in\n",
    "sheets = pd.read_excel(input_filename, sheet_name=None, header=None)\n",
    "\n",
    "# Process each sheet\n",
    "for sheet_name, df in sheets.items():\n",
    "    # Set diagnosis from the first row (row index 0, first cell)\n",
    "    diagnosis = df.iloc[0, 0]\n",
    "\n",
    "    # For each model in the list, call the LLM and add a new column with the estimation.\n",
    "    for model in model_names:\n",
    "        new_col_header = \"lr_\" + model\n",
    "        new_col = []  # This list will hold one value per row\n",
    "        print(f\"Diagnosis: '{diagnosis}', Model: '{model}'\")\n",
    "\n",
    "        # Iterate over each row in the sheet.\n",
    "        # Row 0 is the diagnosis row; row 1 is the existing column labels.\n",
    "        for i in range(len(df)):\n",
    "            if i == 0:\n",
    "                new_col.append(\"\")  # Leave the diagnosis row unchanged.\n",
    "            elif i == 1:\n",
    "                new_col.append(new_col_header)  # Insert the new column header in row 1.\n",
    "            else:\n",
    "                # For data rows, use the \"finding\" from the first column (index 0)\n",
    "                info_val = df.iloc[i, 0]\n",
    "                try:\n",
    "                    estimated_lr = estimate_lr(diagnosis, info_val, client, model)\n",
    "                except Exception as e:\n",
    "                    estimated_lr = \"ERROR\"  \n",
    "                    print(f\"Error estimating LR for sheet '{sheet_name}', row {i}, model {model}: {e}\")\n",
    "                new_col.append(estimated_lr)\n",
    "        \n",
    "        # Insert the new column at the end of the dataframe.\n",
    "        df.insert(df.shape[1], new_col_header, new_col)\n",
    "    \n",
    "    # Update the sheet data in our dictionary.\n",
    "    sheets[sheet_name] = df\n",
    "\n",
    "# Write out the modified sheets to a new Excel file.\n",
    "output_filename = \"nnt_lrs_with_estimated.xlsx\"\n",
    "with pd.ExcelWriter(output_filename, engine=\"openpyxl\") as writer:\n",
    "    for sheet_name, df in sheets.items():\n",
    "        # Write without adding pandas default headers or indices.\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)\n",
    "\n",
    "print(f\"Processed Excel file saved as '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Diagnostic Accuracy of Ultrasound for Confirmation of Endotr | gpt-4o-mini-2024-07-18\n",
      "→ Diagnostic Accuracy of Ultrasound for Confirmation of Endotr | gpt-4o-2024-08-06\n",
      "→ Diagnostic Accuracy of Ultrasound for Confirmation of Endotr | gpt-4.1-mini-2025-04-14\n",
      "→ Diagnostic Accuracy of Ultrasound for Confirmation of Endotr | gpt-4.1-2025-04-14\n",
      "→ Diagnostic Accuracy of Ultrasound for Confirmation of Endotr | o3-mini-2025-01-31\n",
      "→ Diagnostic Accuracy of Ultrasound for Confirmation of Endotr | o3-2025-04-16\n",
      "→ Diagnostic Accuracy of Ultrasound for Confirmation of Endotr | o4-mini-2025-04-16\n",
      "→ Factors Predicting Difficult Endotracheal Intubation | gpt-4o-mini-2024-07-18\n",
      "→ Factors Predicting Difficult Endotracheal Intubation | gpt-4o-2024-08-06\n",
      "→ Factors Predicting Difficult Endotracheal Intubation | gpt-4.1-mini-2025-04-14\n",
      "→ Factors Predicting Difficult Endotracheal Intubation | gpt-4.1-2025-04-14\n",
      "→ Factors Predicting Difficult Endotracheal Intubation | o3-mini-2025-01-31\n",
      "→ Factors Predicting Difficult Endotracheal Intubation | o3-2025-04-16\n",
      "→ Factors Predicting Difficult Endotracheal Intubation | o4-mini-2025-04-16\n",
      "→ Acute Coronary Syndrome | gpt-4o-mini-2024-07-18\n",
      "→ Acute Coronary Syndrome | gpt-4o-2024-08-06\n",
      "→ Acute Coronary Syndrome | gpt-4.1-mini-2025-04-14\n",
      "→ Acute Coronary Syndrome | gpt-4.1-2025-04-14\n",
      "→ Acute Coronary Syndrome | o3-mini-2025-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 6, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 9, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 15, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 17, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 22, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 24, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 30, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 33, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 34, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 36, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 37, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 39, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 40, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 43, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 47, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 52, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 56, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 58, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 59, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 64, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 65, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 66, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 69, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 71, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 73, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 79, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 80, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 81, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 83, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 85, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2045, prompt_tokens=393, total_tokens=2438, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2029, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 86, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 88, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 90, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Acute Coronary Syndrome | o3-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 8, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 11, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 13, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 15, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 21, model o3-2025-04-16: Error code: 400 - {'error': {'message': 'Could not finish the message because max_tokens or model output limit was reached. Please try again with higher max_tokens.', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 22, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 24, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 29, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 47, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 54, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 58, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 69, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 78, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 85, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Acute Coronary Syndrome | o4-mini-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 2, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 6, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 17, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 27, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 29, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 32, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 41, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 44, model o4-mini-2025-04-16: 'NoneType' object has no attribute 'value'\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 56, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 66, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Acute Coronary Syndrome', row 77, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Aortic Dissection | gpt-4o-mini-2024-07-18\n",
      "→ Aortic Dissection | gpt-4o-2024-08-06\n",
      "→ Aortic Dissection | gpt-4.1-mini-2025-04-14\n",
      "→ Aortic Dissection | gpt-4.1-2025-04-14\n",
      "→ Aortic Dissection | o3-mini-2025-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Aortic Dissection', row 9, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Aortic Dissection | o3-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Aortic Dissection', row 3, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Aortic Dissection', row 4, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Aortic Dissection', row 6, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Aortic Dissection', row 9, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Aortic Dissection', row 12, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Aortic Dissection', row 18, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Aortic Dissection | o4-mini-2025-04-16\n",
      "→ Deep Venous Thrombosis (DVT) | gpt-4o-mini-2024-07-18\n",
      "→ Deep Venous Thrombosis (DVT) | gpt-4o-2024-08-06\n",
      "→ Deep Venous Thrombosis (DVT) | gpt-4.1-mini-2025-04-14\n",
      "→ Deep Venous Thrombosis (DVT) | gpt-4.1-2025-04-14\n",
      "→ Deep Venous Thrombosis (DVT) | o3-mini-2025-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Deep Venous Thrombosis (DVT)', row 7, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=399, total_tokens=2447, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Deep Venous Thrombosis (DVT) | o3-2025-04-16\n",
      "→ Deep Venous Thrombosis (DVT) | o4-mini-2025-04-16\n",
      "→ Dyspnea Due to Acute Heart Failure Syndrome | gpt-4o-mini-2024-07-18\n",
      "→ Dyspnea Due to Acute Heart Failure Syndrome | gpt-4o-2024-08-06\n",
      "→ Dyspnea Due to Acute Heart Failure Syndrome | gpt-4.1-mini-2025-04-14\n",
      "→ Dyspnea Due to Acute Heart Failure Syndrome | gpt-4.1-2025-04-14\n",
      "→ Dyspnea Due to Acute Heart Failure Syndrome | o3-mini-2025-01-31\n",
      "→ Dyspnea Due to Acute Heart Failure Syndrome | o3-2025-04-16\n",
      "→ Dyspnea Due to Acute Heart Failure Syndrome | o4-mini-2025-04-16\n",
      "→ Dyspnea Due to Heart Failure (With Chronic Respiratory Disea | gpt-4o-mini-2024-07-18\n",
      "→ Dyspnea Due to Heart Failure (With Chronic Respiratory Disea | gpt-4o-2024-08-06\n",
      "→ Dyspnea Due to Heart Failure (With Chronic Respiratory Disea | gpt-4.1-mini-2025-04-14\n",
      "→ Dyspnea Due to Heart Failure (With Chronic Respiratory Disea | gpt-4.1-2025-04-14\n",
      "→ Dyspnea Due to Heart Failure (With Chronic Respiratory Disea | o3-mini-2025-01-31\n",
      "→ Dyspnea Due to Heart Failure (With Chronic Respiratory Disea | o3-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'th Chronic Respiratory Disease)', row 9, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=401, total_tokens=2449, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'th Chronic Respiratory Disease)', row 43, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=401, total_tokens=2449, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'th Chronic Respiratory Disease)', row 51, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=401, total_tokens=2449, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Dyspnea Due to Heart Failure (With Chronic Respiratory Disea | o4-mini-2025-04-16\n",
      "→ Dyspnea Due to Heart Failure (Without Chronic Respiratory Di | gpt-4o-mini-2024-07-18\n",
      "→ Dyspnea Due to Heart Failure (Without Chronic Respiratory Di | gpt-4o-2024-08-06\n",
      "→ Dyspnea Due to Heart Failure (Without Chronic Respiratory Di | gpt-4.1-mini-2025-04-14\n",
      "→ Dyspnea Due to Heart Failure (Without Chronic Respiratory Di | gpt-4.1-2025-04-14\n",
      "→ Dyspnea Due to Heart Failure (Without Chronic Respiratory Di | o3-mini-2025-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'ut Chronic Respiratory Disease)', row 28, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=403, total_tokens=2451, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'ut Chronic Respiratory Disease)', row 63, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=403, total_tokens=2451, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Dyspnea Due to Heart Failure (Without Chronic Respiratory Di | o3-2025-04-16\n",
      "→ Dyspnea Due to Heart Failure (Without Chronic Respiratory Di | o4-mini-2025-04-16\n",
      "→ Markers of Fluid Responsiveness in Hemodynamically Unstable  | gpt-4o-mini-2024-07-18\n",
      "→ Markers of Fluid Responsiveness in Hemodynamically Unstable  | gpt-4o-2024-08-06\n",
      "→ Markers of Fluid Responsiveness in Hemodynamically Unstable  | gpt-4.1-mini-2025-04-14\n",
      "→ Markers of Fluid Responsiveness in Hemodynamically Unstable  | gpt-4.1-2025-04-14\n",
      "→ Markers of Fluid Responsiveness in Hemodynamically Unstable  | o3-mini-2025-01-31\n",
      "→ Markers of Fluid Responsiveness in Hemodynamically Unstable  | o3-2025-04-16\n",
      "→ Markers of Fluid Responsiveness in Hemodynamically Unstable  | o4-mini-2025-04-16\n",
      "→ Use of the Clinical Examination in the Diagnosis of Cardiac  | gpt-4o-mini-2024-07-18\n",
      "→ Use of the Clinical Examination in the Diagnosis of Cardiac  | gpt-4o-2024-08-06\n",
      "→ Use of the Clinical Examination in the Diagnosis of Cardiac  | gpt-4.1-mini-2025-04-14\n",
      "→ Use of the Clinical Examination in the Diagnosis of Cardiac  | gpt-4.1-2025-04-14\n",
      "→ Use of the Clinical Examination in the Diagnosis of Cardiac  | o3-mini-2025-01-31\n",
      "→ Use of the Clinical Examination in the Diagnosis of Cardiac  | o3-2025-04-16\n",
      "→ Use of the Clinical Examination in the Diagnosis of Cardiac  | o4-mini-2025-04-16\n",
      "→ Accuracy of Physical Examination and Imaging Findings for th | gpt-4o-mini-2024-07-18\n",
      "→ Accuracy of Physical Examination and Imaging Findings for th | gpt-4o-2024-08-06\n",
      "→ Accuracy of Physical Examination and Imaging Findings for th | gpt-4.1-mini-2025-04-14\n",
      "→ Accuracy of Physical Examination and Imaging Findings for th | gpt-4.1-2025-04-14\n",
      "→ Accuracy of Physical Examination and Imaging Findings for th | o3-mini-2025-01-31\n",
      "→ Accuracy of Physical Examination and Imaging Findings for th | o3-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet ' Elevated Intracranial Pressure', row 6, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=404, total_tokens=2452, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Accuracy of Physical Examination and Imaging Findings for th | o4-mini-2025-04-16\n",
      "→ Ankle-Brachial Index for Diagnosis of Arterial Injury in Pen | gpt-4o-mini-2024-07-18\n",
      "→ Ankle-Brachial Index for Diagnosis of Arterial Injury in Pen | gpt-4o-2024-08-06\n",
      "→ Ankle-Brachial Index for Diagnosis of Arterial Injury in Pen | gpt-4.1-mini-2025-04-14\n",
      "→ Ankle-Brachial Index for Diagnosis of Arterial Injury in Pen | gpt-4.1-2025-04-14\n",
      "→ Ankle-Brachial Index for Diagnosis of Arterial Injury in Pen | o3-mini-2025-01-31\n",
      "→ Ankle-Brachial Index for Diagnosis of Arterial Injury in Pen | o3-2025-04-16\n",
      "→ Ankle-Brachial Index for Diagnosis of Arterial Injury in Pen | o4-mini-2025-04-16\n",
      "→ Diagnostic Accuracy of Point-of-Care Ultrasound for Retinal  | gpt-4o-mini-2024-07-18\n",
      "→ Diagnostic Accuracy of Point-of-Care Ultrasound for Retinal  | gpt-4o-2024-08-06\n",
      "→ Diagnostic Accuracy of Point-of-Care Ultrasound for Retinal  | gpt-4.1-mini-2025-04-14\n",
      "→ Diagnostic Accuracy of Point-of-Care Ultrasound for Retinal  | gpt-4.1-2025-04-14\n",
      "→ Diagnostic Accuracy of Point-of-Care Ultrasound for Retinal  | o3-mini-2025-01-31\n",
      "→ Diagnostic Accuracy of Point-of-Care Ultrasound for Retinal  | o3-2025-04-16\n",
      "→ Diagnostic Accuracy of Point-of-Care Ultrasound for Retinal  | o4-mini-2025-04-16\n",
      "→ Diagnostic Accuracy of the History, Physical Examination, an | gpt-4o-mini-2024-07-18\n",
      "→ Diagnostic Accuracy of the History, Physical Examination, an | gpt-4o-2024-08-06\n",
      "→ Diagnostic Accuracy of the History, Physical Examination, an | gpt-4.1-mini-2025-04-14\n",
      "→ Diagnostic Accuracy of the History, Physical Examination, an | gpt-4.1-2025-04-14\n",
      "→ Diagnostic Accuracy of the History, Physical Examination, an | o3-mini-2025-01-31\n",
      "→ Diagnostic Accuracy of the History, Physical Examination, an | o3-2025-04-16\n",
      "→ Diagnostic Accuracy of the History, Physical Examination, an | o4-mini-2025-04-16\n",
      "→ Diagnostic Accuracy of Ultrasound for the Evaluation of Smal | gpt-4o-mini-2024-07-18\n",
      "→ Diagnostic Accuracy of Ultrasound for the Evaluation of Smal | gpt-4o-2024-08-06\n",
      "→ Diagnostic Accuracy of Ultrasound for the Evaluation of Smal | gpt-4.1-mini-2025-04-14\n",
      "→ Diagnostic Accuracy of Ultrasound for the Evaluation of Smal | gpt-4.1-2025-04-14\n",
      "→ Diagnostic Accuracy of Ultrasound for the Evaluation of Smal | o3-mini-2025-01-31\n",
      "→ Diagnostic Accuracy of Ultrasound for the Evaluation of Smal | o3-2025-04-16\n",
      "→ Diagnostic Accuracy of Ultrasound for the Evaluation of Smal | o4-mini-2025-04-16\n",
      "→ Operating Characteristics of Diagnostic Tests for Syphilis | gpt-4o-mini-2024-07-18\n",
      "→ Operating Characteristics of Diagnostic Tests for Syphilis | gpt-4o-2024-08-06\n",
      "→ Operating Characteristics of Diagnostic Tests for Syphilis | gpt-4.1-mini-2025-04-14\n",
      "→ Operating Characteristics of Diagnostic Tests for Syphilis | gpt-4.1-2025-04-14\n",
      "→ Operating Characteristics of Diagnostic Tests for Syphilis | o3-mini-2025-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'f Diagnostic Tests for Syphilis', row 5, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=398, total_tokens=2446, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Operating Characteristics of Diagnostic Tests for Syphilis | o3-2025-04-16\n",
      "→ Operating Characteristics of Diagnostic Tests for Syphilis | o4-mini-2025-04-16\n",
      "→ Lung Ultrasound for Diagnosis of Pneumonia in Children | gpt-4o-mini-2024-07-18\n",
      "→ Lung Ultrasound for Diagnosis of Pneumonia in Children | gpt-4o-2024-08-06\n",
      "→ Lung Ultrasound for Diagnosis of Pneumonia in Children | gpt-4.1-mini-2025-04-14\n",
      "→ Lung Ultrasound for Diagnosis of Pneumonia in Children | gpt-4.1-2025-04-14\n",
      "→ Lung Ultrasound for Diagnosis of Pneumonia in Children | o3-mini-2025-01-31\n",
      "→ Lung Ultrasound for Diagnosis of Pneumonia in Children | o3-2025-04-16\n",
      "→ Lung Ultrasound for Diagnosis of Pneumonia in Children | o4-mini-2025-04-16\n",
      "→ Point-of-Care Ultrasound for the Diagnosis of Thoracoabdomin | gpt-4o-mini-2024-07-18\n",
      "→ Point-of-Care Ultrasound for the Diagnosis of Thoracoabdomin | gpt-4o-2024-08-06\n",
      "→ Point-of-Care Ultrasound for the Diagnosis of Thoracoabdomin | gpt-4.1-mini-2025-04-14\n",
      "→ Point-of-Care Ultrasound for the Diagnosis of Thoracoabdomin | gpt-4.1-2025-04-14\n",
      "→ Point-of-Care Ultrasound for the Diagnosis of Thoracoabdomin | o3-mini-2025-01-31\n",
      "→ Point-of-Care Ultrasound for the Diagnosis of Thoracoabdomin | o3-2025-04-16\n",
      "→ Point-of-Care Ultrasound for the Diagnosis of Thoracoabdomin | o4-mini-2025-04-16\n",
      "→ Retinal Pathology in Patients with Acute Onset Flashes and F | gpt-4o-mini-2024-07-18\n",
      "→ Retinal Pathology in Patients with Acute Onset Flashes and F | gpt-4o-2024-08-06\n",
      "→ Retinal Pathology in Patients with Acute Onset Flashes and F | gpt-4.1-mini-2025-04-14\n",
      "→ Retinal Pathology in Patients with Acute Onset Flashes and F | gpt-4.1-2025-04-14\n",
      "→ Retinal Pathology in Patients with Acute Onset Flashes and F | o3-mini-2025-01-31\n",
      "→ Retinal Pathology in Patients with Acute Onset Flashes and F | o3-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'cute Onset Flashes and Floaters', row 4, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=402, total_tokens=2450, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'cute Onset Flashes and Floaters', row 5, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=402, total_tokens=2450, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'cute Onset Flashes and Floaters', row 6, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=402, total_tokens=2450, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Retinal Pathology in Patients with Acute Onset Flashes and F | o4-mini-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'cute Onset Flashes and Floaters', row 2, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=402, total_tokens=2450, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'cute Onset Flashes and Floaters', row 4, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=402, total_tokens=2450, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Hypovolemia | gpt-4o-mini-2024-07-18\n",
      "→ Hypovolemia | gpt-4o-2024-08-06\n",
      "→ Hypovolemia | gpt-4.1-mini-2025-04-14\n",
      "→ Hypovolemia | gpt-4.1-2025-04-14\n",
      "→ Hypovolemia | o3-mini-2025-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Hypovolemia', row 4, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hypovolemia', row 6, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hypovolemia', row 9, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hypovolemia', row 20, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hypovolemia', row 23, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Hypovolemia | o3-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Hypovolemia', row 6, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hypovolemia', row 20, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Hypovolemia | o4-mini-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Hypovolemia', row 4, model o4-mini-2025-04-16: Error code: 400 - {'error': {'message': 'Could not finish the message because max_tokens or model output limit was reached. Please try again with higher max_tokens.', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "WARNING:root:Error on sheet 'Hypovolemia', row 13, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Malaria in Returning Travelers | gpt-4o-mini-2024-07-18\n",
      "→ Malaria in Returning Travelers | gpt-4o-2024-08-06\n",
      "→ Malaria in Returning Travelers | gpt-4.1-mini-2025-04-14\n",
      "→ Malaria in Returning Travelers | gpt-4.1-2025-04-14\n",
      "→ Malaria in Returning Travelers | o3-mini-2025-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Malaria in Returning Travelers', row 24, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Malaria in Returning Travelers', row 26, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Malaria in Returning Travelers | o3-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Malaria in Returning Travelers', row 14, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Malaria in Returning Travelers', row 17, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Malaria in Returning Travelers | o4-mini-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Malaria in Returning Travelers', row 17, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Osteomyelitis in Diabetic Patients | gpt-4o-mini-2024-07-18\n",
      "→ Osteomyelitis in Diabetic Patients | gpt-4o-2024-08-06\n",
      "→ Osteomyelitis in Diabetic Patients | gpt-4.1-mini-2025-04-14\n",
      "→ Osteomyelitis in Diabetic Patients | gpt-4.1-2025-04-14\n",
      "→ Osteomyelitis in Diabetic Patients | o3-mini-2025-01-31\n",
      "→ Osteomyelitis in Diabetic Patients | o3-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'eomyelitis in Diabetic Patients', row 2, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=395, total_tokens=2443, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'eomyelitis in Diabetic Patients', row 4, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=395, total_tokens=2443, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'eomyelitis in Diabetic Patients', row 15, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=395, total_tokens=2443, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Osteomyelitis in Diabetic Patients | o4-mini-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'eomyelitis in Diabetic Patients', row 12, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=395, total_tokens=2443, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'eomyelitis in Diabetic Patients', row 16, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=395, total_tokens=2443, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Pertussis (Whooping Cough) | gpt-4o-mini-2024-07-18\n",
      "→ Pertussis (Whooping Cough) | gpt-4o-2024-08-06\n",
      "→ Pertussis (Whooping Cough) | gpt-4.1-mini-2025-04-14\n",
      "→ Pertussis (Whooping Cough) | gpt-4.1-2025-04-14\n",
      "→ Pertussis (Whooping Cough) | o3-mini-2025-01-31\n",
      "→ Pertussis (Whooping Cough) | o3-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Pertussis (Whooping Cough)', row 3, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Pertussis (Whooping Cough)', row 4, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Pertussis (Whooping Cough) | o4-mini-2025-04-16\n",
      "→ Streptococal Pharyngitis | gpt-4o-mini-2024-07-18\n",
      "→ Streptococal Pharyngitis | gpt-4o-2024-08-06\n",
      "→ Streptococal Pharyngitis | gpt-4.1-mini-2025-04-14\n",
      "→ Streptococal Pharyngitis | gpt-4.1-2025-04-14\n",
      "→ Streptococal Pharyngitis | o3-mini-2025-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 5, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 11, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 12, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 13, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 14, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 15, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 18, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 20, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 23, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 24, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 25, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 29, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 31, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 39, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 40, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 42, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 44, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 47, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 50, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Streptococal Pharyngitis | o3-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 3, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 4, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 22, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 23, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 26, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 29, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 31, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 32, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 34, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 36, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 40, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 41, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 47, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 50, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Streptococal Pharyngitis | o4-mini-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 10, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 16, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 19, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 23, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 24, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 31, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 40, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Streptococal Pharyngitis', row 47, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Hemorrhagic Stroke | gpt-4o-mini-2024-07-18\n",
      "→ Hemorrhagic Stroke | gpt-4o-2024-08-06\n",
      "→ Hemorrhagic Stroke | gpt-4.1-mini-2025-04-14\n",
      "→ Hemorrhagic Stroke | gpt-4.1-2025-04-14\n",
      "→ Hemorrhagic Stroke | o3-mini-2025-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 17, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=394, total_tokens=2442, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Hemorrhagic Stroke | o3-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 4, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 9, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 10, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 12, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 14, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 16, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 20, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 22, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 33, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 35, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 37, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 38, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 48, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 53, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 57, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Hemorrhagic Stroke | o4-mini-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Hemorrhagic Stroke', row 38, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=392, total_tokens=2440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Migraine | gpt-4o-mini-2024-07-18\n",
      "→ Migraine | gpt-4o-2024-08-06\n",
      "→ Migraine | gpt-4.1-mini-2025-04-14\n",
      "→ Migraine | gpt-4.1-2025-04-14\n",
      "→ Migraine | o3-mini-2025-01-31\n",
      "→ Migraine | o3-2025-04-16\n",
      "→ Migraine | o4-mini-2025-04-16\n",
      "→ Myasthenia Gravis | gpt-4o-mini-2024-07-18\n",
      "→ Myasthenia Gravis | gpt-4o-2024-08-06\n",
      "→ Myasthenia Gravis | gpt-4.1-mini-2025-04-14\n",
      "→ Myasthenia Gravis | gpt-4.1-2025-04-14\n",
      "→ Myasthenia Gravis | o3-mini-2025-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Myasthenia Gravis', row 7, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=395, total_tokens=2443, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Myasthenia Gravis', row 10, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=395, total_tokens=2443, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Myasthenia Gravis', row 11, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=395, total_tokens=2443, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Myasthenia Gravis | o3-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Myasthenia Gravis', row 12, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Myasthenia Gravis | o4-mini-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Myasthenia Gravis', row 7, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Spinal Stenosis in the Elderly | gpt-4o-mini-2024-07-18\n",
      "→ Spinal Stenosis in the Elderly | gpt-4o-2024-08-06\n",
      "→ Spinal Stenosis in the Elderly | gpt-4.1-mini-2025-04-14\n",
      "→ Spinal Stenosis in the Elderly | gpt-4.1-2025-04-14\n",
      "→ Spinal Stenosis in the Elderly | o3-mini-2025-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Spinal Stenosis in the Elderly', row 3, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=398, total_tokens=2446, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Spinal Stenosis in the Elderly', row 17, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=398, total_tokens=2446, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Spinal Stenosis in the Elderly', row 31, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=398, total_tokens=2446, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Spinal Stenosis in the Elderly | o3-2025-04-16\n",
      "→ Spinal Stenosis in the Elderly | o4-mini-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Spinal Stenosis in the Elderly', row 3, model o4-mini-2025-04-16: Error code: 400 - {'error': {'message': 'Could not finish the message because max_tokens or model output limit was reached. Please try again with higher max_tokens.', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "WARNING:root:Error on sheet 'Spinal Stenosis in the Elderly', row 11, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Spinal Stenosis in the Elderly', row 36, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Spinal Stenosis in the Elderly', row 60, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=396, total_tokens=2444, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Temporal Arteritis | gpt-4o-mini-2024-07-18\n",
      "→ Temporal Arteritis | gpt-4o-2024-08-06\n",
      "→ Temporal Arteritis | gpt-4.1-mini-2025-04-14\n",
      "→ Temporal Arteritis | gpt-4.1-2025-04-14\n",
      "→ Temporal Arteritis | o3-mini-2025-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 4, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 8, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 12, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 18, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 21, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 22, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 23, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 25, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 31, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 39, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 47, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 48, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Temporal Arteritis | o3-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 9, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 10, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 21, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 23, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 28, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 32, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 37, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 41, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 47, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 48, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 50, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 57, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Temporal Arteritis | o4-mini-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 13, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 27, model o4-mini-2025-04-16: 'NoneType' object has no attribute 'value'\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 39, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 44, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 47, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Temporal Arteritis', row 49, model o4-mini-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Carpal Tunnel Syndrome | gpt-4o-mini-2024-07-18\n",
      "→ Carpal Tunnel Syndrome | gpt-4o-2024-08-06\n",
      "→ Carpal Tunnel Syndrome | gpt-4.1-mini-2025-04-14\n",
      "→ Carpal Tunnel Syndrome | gpt-4.1-2025-04-14\n",
      "→ Carpal Tunnel Syndrome | o3-mini-2025-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 4, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 5, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 9, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 12, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 13, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 23, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 24, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 25, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 28, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 32, model o3-mini-2025-01-31: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=393, total_tokens=2441, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Carpal Tunnel Syndrome | o3-2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 11, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 12, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 22, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 24, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 27, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 28, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "WARNING:root:Error on sheet 'Carpal Tunnel Syndrome', row 33, model o3-2025-04-16: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=391, total_tokens=2439, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2048, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Carpal Tunnel Syndrome | o4-mini-2025-04-16\n",
      "✅  All done – results saved to 'nnt_lrs_with_estimated.xlsx'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Bayesian LR estimator – tolerant of o‑family hidden‑reasoning bloat\n",
    "2025‑07‑07\n",
    "\"\"\"\n",
    "import os, logging, pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# SYSTEM PROMPT – still enforces JSON-only output\n",
    "# --------------------------------------------------------------------------\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a Bayesian-diagnostic assistant.\\n\"\n",
    "    \"Think step-by-step internally, then output only JSON:\\n\"\n",
    "    '{\"value\": <float> (>0)}.'\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# INTERNAL (HIDDEN) REASONING CHECKLIST\n",
    "# --------------------------------------------------------------------------\n",
    "INTERNAL_CHECKLIST = (\n",
    "    \"Use this silent checklist:\\n\"\n",
    "    \" 1. Recall the typical presentation.\\n\"\n",
    "    \" 2. Consider if the findings is present or absent.\\n\"\n",
    "    \" 3. Compare frequency of the finding (or its absence) in positives vs negatives.\\n\"\n",
    "    \" 4. Use the LR guide as a rough reference.\\n\"\n",
    "    \" 5. Refine your estimate within the LR-guide categories (e.g. 0.3 vs 0.4).\\n\"\n",
    "    \" 6. Return JSON only.\"\n",
    ")\n",
    "\n",
    "LR_LADDER = (\n",
    "    \"LR guide ➜  >20 pathognomonic · 5-20 very strong for · \"\n",
    "    \"2-5 moderate for · 1.4-2 weak for · 0.71-1.4 neutral · \"\n",
    "    \"0.2-0.71 moderate against · 0.05-0.2 very strong against · <0.05 rule-out.\"\n",
    ")\n",
    "\n",
    "# ----------------  9-SHOT PRIMER  (for gpt-family)  -------------------------\n",
    "RICH_PRIMER = \"\"\"\n",
    "<analysis># bucket: pathognomonic | step 1: prevalence high?\n",
    "C: bacterial meningitis\n",
    "F: nuchal rigidity\n",
    "</analysis>\n",
    "<json>{\"value\": 20}</json>\n",
    "\n",
    "<analysis># bucket: very-strong-for\n",
    "C: pulmonary embolism\n",
    "F: Wells score >6\n",
    "</analysis>\n",
    "<json>{\"value\": 10}</json>\n",
    "\n",
    "<analysis># bucket: strong-for\n",
    "C: ectopic pregnancy\n",
    "F: β-hCG >6500 IU + no intra-uterine sac\n",
    "</analysis>\n",
    "<json>{\"value\": 5}</json>\n",
    "\n",
    "<analysis># bucket: weak-for\n",
    "C: cardiac chest pain\n",
    "F: pain behind sternum\n",
    "</analysis>\n",
    "<json>{\"value\": 1.5}</json>\n",
    "\n",
    "<analysis># bucket: moderate-against\n",
    "C: appendicitis\n",
    "F: guarding absent\n",
    "</analysis>\n",
    "<json>{\"value\": 0.5}</json>\n",
    "\n",
    "<analysis># bucket: very-strong-against\n",
    "C: DKA\n",
    "F: normal anion gap\n",
    "</analysis>\n",
    "<json>{\"value\": 0.1}</json>\n",
    "\n",
    "<analysis># bucket: neutral\n",
    "C: myocardial infarction\n",
    "F: enjoys playing chess\n",
    "</analysis>\n",
    "<json>{\"value\": 1}</json>\n",
    "\"\"\".strip()\n",
    "\n",
    "# --------------  2-SHOT PRIMER  (for o-family)  ----------------------------\n",
    "MINIMAL_PRIMER = \"\"\"\n",
    "<analysis># pathognomonic\n",
    "C: bacterial meningitis\n",
    "F: nuchal rigidity\n",
    "</analysis>\n",
    "<json>{\"value\": 20}</json>\n",
    "\n",
    "<analysis># neutral\n",
    "C: myocardial infarction\n",
    "F: enjoys playing chess\n",
    "</analysis>\n",
    "<json>{\"value\": 1}</json>\n",
    "\"\"\".strip()\n",
    "\n",
    "# ------------ CAPABILITY MAP (single source‑of‑truth for all models) ---------\n",
    "\n",
    "MODEL_CAPABILITIES = {\n",
    "    # family  | length‑field              | temp? | hidden‑token caps to try\n",
    "    \"gpt-4o-mini-2024-07-18\"  : {\"field\": \"max_tokens\",            \"temp\": True,  \"caps\": [64]},\n",
    "    \"gpt-4o-2024-08-06\"       : {\"field\": \"max_tokens\",            \"temp\": True,  \"caps\": [64]},\n",
    "    \"gpt-4.1-mini-2025-04-14\" : {\"field\": \"max_tokens\",            \"temp\": True,  \"caps\": [64]},\n",
    "    \"gpt-4.1-2025-04-14\"      : {\"field\": \"max_tokens\",            \"temp\": True,  \"caps\": [64]},\n",
    "    # o‑family – we escalate 512 → 1024 → 2048 if needed\n",
    "    \"o3-mini-2025-01-31\": {\"field\": \"max_completion_tokens\", \"temp\": False,\n",
    "                        \"caps\": [2048]},   # single generous cap\n",
    "    \"o3-2025-04-16\":      {\"field\": \"max_completion_tokens\", \"temp\": False,\n",
    "                        \"caps\": [2048]},\n",
    "    \"o4-mini-2025-04-16\": {\"field\": \"max_completion_tokens\", \"temp\": False,\n",
    "                        \"caps\": [2048]},\n",
    "}\n",
    "\"\"\"\n",
    "# Abbreviated test run\n",
    "MODEL_CAPABILITIES = {\n",
    "    # family  | length‑field              | temp? | hidden‑token caps to try\n",
    "    \"gpt-4o-mini-2024-07-18\"  : {\"field\": \"max_tokens\",            \"temp\": True,  \"caps\": [64]},\n",
    "    \"gpt-4.1-mini-2025-04-14\" : {\"field\": \"max_tokens\",            \"temp\": True,  \"caps\": [64]}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ----------------------------- RESPONSE SCHEMA ------------------------------\n",
    "class LRResponse(BaseModel):\n",
    "    value: float\n",
    "\n",
    "# --------------------------- HELPER FUNCTIONS -------------------------------\n",
    "def build_messages(dx: str, finding: str, for_o: bool) -> list[dict]:\n",
    "    primer = MINIMAL_PRIMER if for_o else RICH_PRIMER\n",
    "    return [\n",
    "        {\"role\": \"system\",    \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"system\",    \"content\": INTERNAL_CHECKLIST},   # ← NEW\n",
    "        {\"role\": \"system\",    \"content\": LR_LADDER},\n",
    "        {\"role\": \"assistant\", \"content\": primer},\n",
    "        {\"role\": \"user\",      \"content\": f\"Condition: {dx}\\nFinding: {finding}\"},\n",
    "    ]\n",
    "\n",
    "def estimate_lr(diagnosis: str, finding: str, client: OpenAI, model: str) -> float:\n",
    "    cfg          = MODEL_CAPABILITIES[model]\n",
    "    is_reasoning = model.startswith(\"o\")\n",
    "\n",
    "    primer      = MINIMAL_PRIMER if is_reasoning else RICH_PRIMER\n",
    "    temperature = 0.20 if is_reasoning else 0.10\n",
    "\n",
    "    for cap in cfg[\"caps\"]:\n",
    "        try:\n",
    "            completion = client.beta.chat.completions.parse(\n",
    "                model=model,\n",
    "                messages=build_messages(primer, diagnosis, finding),\n",
    "                response_format=LRResponse,\n",
    "                **{cfg[\"field\"]: cap},\n",
    "                **({\"temperature\": temperature} if cfg[\"temp\"] else {}),\n",
    "                **({\"reasoning_effort\": \"medium\"} if model.startswith(\"o3\") else {}),\n",
    "            )\n",
    "            return float(completion.choices[0].message.parsed.value)\n",
    "        except Exception as e:\n",
    "            # Only retry on the length‑limit failure signature\n",
    "            if \"length limit was reached\" in str(e) and cap != cfg[\"caps\"][-1]:\n",
    "                logging.warning(f\"Retrying {model} with larger cap \"\n",
    "                                f\"({cap}→{cfg['caps'][cfg['caps'].index(cap)+1]})\")\n",
    "                continue\n",
    "            raise\n",
    "\n",
    "# -------------------------------  MAIN PIPE  --------------------------------\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "models = list(MODEL_CAPABILITIES)\n",
    "input_file, output_file = \"nnt_lrs_processed.xlsx\", \"nnt_lrs_with_estimated.xlsx\"\n",
    "sheets = pd.read_excel(input_file, sheet_name=None, header=None)\n",
    "\n",
    "for sheet_name, df in sheets.items():\n",
    "    diagnosis = df.iloc[0, 0]\n",
    "    for model in models:\n",
    "        new_header, col = \"lr_\" + model, []\n",
    "        print(f\"→ {diagnosis[:60]} | {model}\")\n",
    "        for i in range(len(df)):\n",
    "            if i == 0:           col.append(\"\")\n",
    "            elif i == 1:         col.append(new_header)\n",
    "            else:\n",
    "                try:\n",
    "                    lr = estimate_lr(diagnosis, df.iloc[i, 0], client, model)\n",
    "                except Exception as e:\n",
    "                    lr = \"ERROR\"\n",
    "                    logging.warning(f\"Error on sheet '{sheet_name}', row {i}, \"\n",
    "                                    f\"model {model}: {e}\")\n",
    "                col.append(lr)\n",
    "        df.insert(df.shape[1], new_header, col)\n",
    "    sheets[sheet_name] = df\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n",
    "    for name, frame in sheets.items():\n",
    "        frame.to_excel(writer, sheet_name=name, index=False, header=False)\n",
    "\n",
    "print(f\"✅  All done – results saved to '{output_file}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code block to generate the processing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Converted workbook written to: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/llm_estimate_lrs/new_NNT_LRs_07.08.2025.xlsx (single sheet: 'Master')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# 1.  Optional helper – keep the same “Feature Type” buckets   \n",
    "#  [ ] TODO: this does not seem like it works very well - just usual manual for now #\n",
    "# ------------------------------------------------------------------ #\n",
    "def classify_feature_type(text: str) -> str:\n",
    "    \"\"\"Heuristic that matches the legacy categories.\"\"\"\n",
    "    t = str(text).lower()\n",
    "\n",
    "    history = \"history:\" in t\n",
    "    sign    = (\"sign:\" in t) or (\"symptom\" in t)\n",
    "    score   = any(k in t for k in (\"score\", \"points\", \"rule\"))\n",
    "    test    = any(k in t for k in (\"test:\", \"lab\", \"troponin\", \"d‑dimer\"))\n",
    "    img     = any(k in t for k in (\n",
    "        \"ultrasound\", \"ct\", \"mri\", \"x‑ray\", \"radiograph\", \"imaging\",\n",
    "        \"echo\", \"angiogram\"))\n",
    "\n",
    "    if history and test: return \"History and Test\"\n",
    "    if history and img:  return \"History and imaging\"\n",
    "    if history:          return \"History_\"\n",
    "    if sign:             return \"Sign_symptom\"\n",
    "    if score:            return \"Score\"\n",
    "    if test:             return \"Test finding\"\n",
    "    if img:              return \"Imaging finding\"\n",
    "    return \"Diagnosis\"\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# 2.  Converter – writes **one** sheet (same name as in template)     #\n",
    "# ------------------------------------------------------------------ #\n",
    "def convert_lr_workbook(\n",
    "    *,                       # keyword‑only for clarity\n",
    "    input_file: str | Path,  # e.g. \"nnt_lrs_with_estimated.xlsx\"\n",
    "    template_file: str | Path,  # updated example workbook\n",
    "    output_file: str | Path = \"nnt_lrs_converted.xlsx\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    • Collapses all per‑condition tabs from `input_file` into a master frame.\n",
    "    • Adds the right‑most `condition` column (original tab name).\n",
    "    • Writes a single worksheet whose name matches the (only) sheet\n",
    "      found in `template_file`, with the header row stored as **row 1**\n",
    "      (no Excel column headers) to preserve downstream‑notebook compatibility.\n",
    "    \"\"\"\n",
    "    input_file    = Path(input_file)\n",
    "    template_file = Path(template_file)\n",
    "    output_file   = Path(output_file)\n",
    "\n",
    "    # -------- determine the sole sheet name from the template --------------\n",
    "    template_xls = pd.ExcelFile(template_file, engine=\"openpyxl\")\n",
    "    if len(template_xls.sheet_names) != 1:\n",
    "        raise ValueError(\n",
    "            f\"Template has {len(template_xls.sheet_names)} sheets; \"\n",
    "            \"expected exactly one after pruning.\"\n",
    "        )\n",
    "    target_sheet = template_xls.sheet_names[0]  # e.g. \"Master\"\n",
    "\n",
    "    # ------------------- build master dataframe ----------------------------\n",
    "    in_xls = pd.ExcelFile(input_file, engine=\"openpyxl\")\n",
    "    frames = []\n",
    "\n",
    "    for tab in in_xls.sheet_names:\n",
    "        raw = pd.read_excel(in_xls, sheet_name=tab, header=None)\n",
    "\n",
    "        # Expect: row‑0 = diagnosis, row‑1 = column labels, row‑2+ = data\n",
    "        if raw.shape[0] < 3:\n",
    "            continue  # skip empty or malformed tabs\n",
    "\n",
    "        header = raw.iloc[1]\n",
    "        df = raw.iloc[2:].copy()\n",
    "        df.columns = header\n",
    "        df = df.loc[:, ~df.columns.isna()]  # drop unnamed columns\n",
    "\n",
    "        # back‑fill Feature Type if the sheet didn't have it\n",
    "        if \"Feature Type\" not in df.columns:\n",
    "            df[\"Feature Type\"] = df.iloc[:, 0].apply(classify_feature_type)\n",
    "\n",
    "        df[\"condition\"] = tab          # new right‑most column\n",
    "        frames.append(df)\n",
    "\n",
    "    if not frames:\n",
    "        raise ValueError(\"No valid data found in the input workbook.\")\n",
    "\n",
    "    master = pd.concat(frames, ignore_index=True)\n",
    "    # ensure 'condition' is the final column\n",
    "    master = master[[c for c in master.columns if c != \"condition\"] + [\"condition\"]]\n",
    "\n",
    "    # ------------------------ write single sheet ---------------------------\n",
    "    with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n",
    "        # replicate legacy layout: header row lives **inside** the block\n",
    "        block = pd.concat(\n",
    "            [pd.DataFrame([master.columns], columns=master.columns), master],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        block.to_excel(\n",
    "            writer,\n",
    "            sheet_name=target_sheet[:31],  # Excel 31‑char cap\n",
    "            index=False,\n",
    "            header=False,\n",
    "        )\n",
    "\n",
    "    print(f\"✅  Converted workbook written to: {output_file} \"\n",
    "          f\"(single sheet: '{target_sheet}')\")\n",
    "    \n",
    "\n",
    "# Run the conversion\n",
    "convert_lr_workbook(\n",
    "    input_file   = '/Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/llm_estimate_lrs/nnt_lrs_with_estimated.xlsx',   # produced after LR loop\n",
    "    template_file= '/Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/llm_estimate_lrs/Past Runs/example_NNT_LRs_PC_07.03.2025.xlsx',  # updated example\n",
    "    output_file  = '/Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/llm_estimate_lrs/new_NNT_LRs_07.08.2025.xlsx',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code block for trouble shooting the Scraper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# url = \\'https://thennt.com/lr/dyspnea-due-to-heart-failure-without-chronic-respiratory-disease/\\'\\nurl = \\'https://thennt.com/lr/diagnostic-accuracy-history-physical-examination-laboratory-testing-giant-cell-arteritis/\\'\\nresponse = requests.get(url)\\n\\nif response.status_code != 200:\\n    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\\n\\nsoup = BeautifulSoup(response.text, \\'html.parser\\')\\nprint(soup)\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# url = 'https://thennt.com/lr/dyspnea-due-to-heart-failure-without-chronic-respiratory-disease/'\n",
    "url = 'https://thennt.com/lr/diagnostic-accuracy-history-physical-examination-laboratory-testing-giant-cell-arteritis/'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "print(soup)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
